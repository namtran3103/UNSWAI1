{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and global declarations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoang-Nam Tran, z5629534\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, mean_absolute_error\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import r_regression\n",
    "import csv\n",
    "\n",
    "\n",
    "# Data columns before pre-processing\n",
    "# ['year', 'month', 'u10', 'v10', 'mx2t', 'mn2t', 'tcc', 't2', 'msl', 't', 'q', 'u', 'v', 'z', 'SPI', 'grid_ID']\n",
    "\n",
    "# Data columns after pre-processing\n",
    "# ['year', 'month', 'u10', 'v10', 'mx2t', 'mn2t', 'tcc', 't2', 'msl', 't', 'q', 'u', 'v', 'z', 'SPI', 'grid_ID','Drought', 'monthCos', 'monthSin']\n",
    "# monthCos and monthSin are the cosine and sine of the normalised month, respectively\n",
    "\n",
    "#used to determine and print the used predictors\n",
    "allPredictors = ['year', 'month', 'u10', 'v10', 'mx2t', 'mn2t', 'tcc', 't2', 'msl', 't', 'q', 'u', 'v', 'z', 'SPI', 'grid_ID', 'Drought', 'monthCos', 'monthSin']\n",
    "\n",
    "# forbidden indices: year, SPI, grid_ID, Drought -> 0, 14, 15, 16\n",
    "forbiddenColumns = [0, 14, 15, 16]\n",
    "\n",
    "#seed for reproducibility\n",
    "shuffleSeed = 42\n",
    "\n",
    "#seeding keras for reproducibility of training\n",
    "keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method declarations for pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing drought variable based on SPI (index 14)\n",
    "def addDrought(data):\n",
    "    for x in data:\n",
    "        try:\n",
    "            if float(x[14]) <= -1:\n",
    "                x.append(1)\n",
    "            else:\n",
    "                x.append(0)\n",
    "        except:\n",
    "            #placeholder 'Drought' if no calculation possible\n",
    "            x.append('Drought')\n",
    "    return data\n",
    "\n",
    "\n",
    "#removing rows with non-numerical values\n",
    "def checkNonFloatNonNP(data):\n",
    "    for x in data:\n",
    "        for y in x:\n",
    "            try:\n",
    "                float(y)\n",
    "            except:\n",
    "                data.remove(x)\n",
    "                break\n",
    "\n",
    "\n",
    "#removing rows containing invalid months\n",
    "def filterInvalidMonthsNP(data):\n",
    "    new_data = []\n",
    "    validMonths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    for x in data:\n",
    "        if x[1] in validMonths:\n",
    "            new_data.append(x)\n",
    "    return np.array(new_data)\n",
    "\n",
    "\n",
    "#normalising months, cyclic encoding with sin and cos\n",
    "def normaliseMonth(dataSet):\n",
    "    new_dataSet = []\n",
    "    for x in dataSet:\n",
    "        month = x[1]\n",
    "        month_normalised = 2 * np.pi * (month - 1) / 12\n",
    "        x = np.append(x, [np.cos(month_normalised), np.sin(month_normalised)])\n",
    "        new_dataSet.append(x)\n",
    "    return np.array(new_dataSet)\n",
    "\n",
    "\n",
    "#removing rows with infinite values\n",
    "def noIncludeInfinites(data):\n",
    "    new_data = []\n",
    "    detected = False\n",
    "    for x in data:\n",
    "        for y in x:\n",
    "            if y == float('inf') or y == float('-inf'):\n",
    "                detected = True\n",
    "                break\n",
    "        if detected == False:\n",
    "            new_data.append(x)\n",
    "    return np.array(new_data)\n",
    "\n",
    "\n",
    "#detecting outliers (column-wise) with z-score method, threshold = 3\n",
    "def detectOutliersByColumn(data, column):\n",
    "    mean = np.mean(data[:, column])\n",
    "    std_dev = np.std(data[:, column])\n",
    "    z_scores = (data[:, column] - mean) / std_dev\n",
    "    outliers = np.abs(z_scores) > 3\n",
    "    outlier_indices = np.where(outliers)\n",
    "    return outlier_indices\n",
    "\n",
    "\n",
    "#removing rows with outliers\n",
    "def removeOutliers(data, excludedColumns):\n",
    "    outliersIndices = set()\n",
    "    #iterating through all columns\n",
    "    for i in range(0, len(data[0])):\n",
    "        #excluding the forbidden columns\n",
    "        if i not in excludedColumns:\n",
    "            outlierIndicesColumn = detectOutliersByColumn(data, i)\n",
    "            for x in outlierIndicesColumn[0]:\n",
    "                outliersIndices.add(x)\n",
    "\n",
    "    outliersIndices = list(outliersIndices)\n",
    "    outliersIndices.sort()\n",
    "    data = np.delete(data, outliersIndices, axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method declarations for evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3f, Create a plot showing the accuracy (y-axis) versus the number of epochs (x-axis) for both the training and validation sets.\n",
    "def plotAccuracy(result):\n",
    "    plt.plot(result.history['accuracy'], 'b', label='Training accuracy')\n",
    "    plt.plot(result.history['val_accuracy'], 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#4e, Creating a plot showing the loss value (y-axis) versus the number of epochs (x-axis) for both the training and validation sets.\n",
    "def plotLoss(result):\n",
    "    plt.plot(result.history['loss'], 'b', label='Training loss')\n",
    "    plt.plot(result.history['val_loss'], 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Create a scatter plot showing predicted SPI (y-axis) versus true SPI (x-axis)\n",
    "def scatterPlot(target, predicted):\n",
    "    plt.scatter(target, predicted)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title('SPI vs Predicted SPI')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Compute and plot a confusion matrix. Positive class is 1, i.e. ‘Drought’.\n",
    "def plotSimpleConfusionMatrix(target, predicted):\n",
    "    confusion_matrix = metrics.confusion_matrix(target, predicted)\n",
    "    cmDisplay = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"No Drought\", \"Drought\"])\n",
    "    cmDisplay.plot()\n",
    "    plt.show()\n",
    "\n",
    "#Printing used predictors, selecting the predictors from allVariables based on the given indices\n",
    "def printPredictorsSet(allVariables, indices):\n",
    "    usedPredictors = []\n",
    "    for x in indices:\n",
    "        usedPredictors.append(allVariables[x])\n",
    "    print(\"Used predictors: \", usedPredictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating drought from SPI and pre-processing of data – 3a, 3c, 4b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment from here to skip training\n",
    "\n",
    "with open('Climate_SPI.csv', newline='') as csvfileUnseen:\n",
    "    initData = list(csv.reader(csvfileUnseen))\n",
    "\n",
    "#pre-processing, adding drought variable, removing invalid rows\n",
    "initData = addDrought(initData)\n",
    "checkNonFloatNonNP(initData)\n",
    "\n",
    "#shuffling the data for randomness in training\n",
    "random.Random(shuffleSeed).shuffle(initData)\n",
    "\n",
    "initData = np.array(initData)\n",
    "initData = initData.astype(float)\n",
    "\n",
    "\n",
    "#removing outliers (z-score, threshold=3), invalid months, infinite values, normalising months\n",
    "initData = removeOutliers(initData, forbiddenColumns)\n",
    "initData = filterInvalidMonthsNP(initData)\n",
    "initData = noIncludeInfinites(initData)\n",
    "initData = normaliseMonth(initData)\n",
    "\n",
    "\n",
    "#predictors used for training and prediction\n",
    "#same predictors for classification and regression since using different predictors did not show improvement\n",
    "inputColumns = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18]\n",
    "\n",
    "#3h, 4g, testing different subsets of predictors\n",
    "#in the end, using all predictors was the best option\n",
    "# inputColumns = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18]\n",
    "# inputColumns = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18]\n",
    "# inputColumns = [2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
    "# inputColumns = [4, 6, 7, 8, 10, 11, 12, 13], test removing related predictors\n",
    "\n",
    "\n",
    "#selecting correct columns for input data\n",
    "unseenInput = initData[:, inputColumns]\n",
    "\n",
    "\n",
    "#normalising the input data with min-max normalisation\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(unseenInput)\n",
    "unseenInputNormalised = scaler.transform(unseenInput)\n",
    "\n",
    "\n",
    "#selecting target-columns for classification and regression, Drought (index 16) and SPI (index 14)\n",
    "unseenTargetClassification = initData[:, 16]\n",
    "unseenTargetRegression = initData[:, 14]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data into training (70%), validation (15%) and test sets (15%) – 3b, 4a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data was shuffled before, randomness ensured\n",
    "\n",
    "#Split data by selecting correct rows for training, validation and testing\n",
    "#Split happens after pre-processing, so same transformation is applied to all sets\n",
    "inputTrain = unseenInputNormalised[:int(0.7*len(initData))]\n",
    "inputVal = unseenInputNormalised[int(0.7*len(initData)):int(0.85*len(initData))]\n",
    "inputTest = unseenInputNormalised[int(0.85*len(initData)):]\n",
    "\n",
    "\n",
    "targetTrainClass = unseenTargetClassification[:int(0.7*len(initData))]\n",
    "targetValClass = unseenTargetClassification[int(0.7*len(initData)):int(0.85*len(initData))]\n",
    "targetTestClass = unseenTargetClassification[int(0.85*len(initData)):]\n",
    "\n",
    "\n",
    "targetTrainRegression = unseenTargetRegression[:int(0.7*len(initData))]\n",
    "targetValRegression = unseenTargetRegression[int(0.7*len(initData)):int(0.85*len(initData))]\n",
    "targetTestRegression = unseenTargetRegression[int(0.85*len(initData)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building and training the classification model – 3d, 3e**\n",
    "\n",
    "**Plot of the accuracy (y-axis) versus the number of epochs (x-axis) for both the training and validation sets – 3f**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationModel = Sequential()\n",
    "#hidden layer with 80 neurons\n",
    "classificationModel.add(Dense(80, activation='relu', input_dim=14))\n",
    "classificationModel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "classificationModel.compile(loss='binary_crossentropy', optimizer=adam, metrics=[\"accuracy\"])\n",
    "resultClass = classificationModel.fit(inputTrain, targetTrainClass, epochs=200, batch_size=64, validation_data=(inputVal, targetValClass))\n",
    "\n",
    "plotAccuracy(resultClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building and training the regression model – 4c, 4d**\n",
    "\n",
    "**Plot showing the loss value (y-axis) versus the number of epochs (x-axis) for both the training and validation sets – 4e**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionModel = Sequential()\n",
    "#hidden layer with 80 neurons\n",
    "regressionModel.add(Dense(80, activation=\"relu\", input_dim=14))\n",
    "regressionModel.add(Dense(1))\n",
    "\n",
    "adamReg = keras.optimizers.Adam(learning_rate=0.001)\n",
    "regressionModel.compile(loss='mean_squared_error', optimizer=adamReg, metrics=[\"mean_squared_error\"])\n",
    "resultRegression = regressionModel.fit(inputTrain, targetTrainRegression, epochs=100, batch_size=64, validation_data=(inputVal, targetValRegression))\n",
    "\n",
    "plotLoss(resultRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating classification model on test set**\n",
    "\n",
    "**Confusion matrix, performance metrics “Balanced Accuracy” and “Precision” calculated on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting drought on the test set, binary classification with threshold 0.5, 3j\n",
    "predictedClass = classificationModel.predict(inputTest)\n",
    "predictedClassBinary = (predictedClass >= 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "#plotting the confusion matrix and performance metrics, 3k\n",
    "plotSimpleConfusionMatrix(targetTestClass, predictedClassBinary)\n",
    "print(\"Balanced Accuracy: \", balanced_accuracy_score(targetTestClass, predictedClassBinary))\n",
    "print(\"Precision: \", precision_score(targetTestClass, predictedClassBinary, pos_label=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating regression model on test set**\n",
    "\n",
    "**On the test set: scatter plot, “Mean Absolute Error (MAE)” and the “Pearson Correlation\n",
    "Coefficient” between the true and predicted SPI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting SPI on the test set, 4i\n",
    "predictedRegression = regressionModel.predict(inputTest)\n",
    "\n",
    "#scatter plot and performance metrics, 4j\n",
    "scatterPlot(targetTestRegression, predictedRegression)\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(targetTestRegression, predictedRegression))\n",
    "print(\"Pearson Correlation Coefficient: \", r_regression(predictedRegression, targetTestRegression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving models and loading saved models for task 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationModel.save(\"classificationDemo.keras\")\n",
    "regressionModel.save(\"regressionDemo.keras\")\n",
    "\n",
    "#uncomment until here to skip training\n",
    "\n",
    "classificationModelLoaded = keras.models.load_model(\"classificationDemo.keras\") #5.1d\n",
    "regressionModelLoaded = keras.models.load_model(\"regressionDemo.keras\") #5.2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to change file name during discussion, 5a\n",
    "with open('Fake_Climate_SPI6.csv', newline='') as csvfileUnseen:\n",
    "    unseenData = list(csv.reader(csvfileUnseen))\n",
    "\n",
    "#pre-processing and normalisation of the unseen data with the same steps as on the previous data, 5.1c, 5.2b\n",
    "#Adding drought variable, removing invalid rows\n",
    "unseenData = addDrought(unseenData) #5.1b\n",
    "checkNonFloatNonNP(unseenData)\n",
    "\n",
    "unseenData = np.array(unseenData)\n",
    "unseenData = unseenData.astype(float)\n",
    "\n",
    "#removing outliers (z-score, threshold=3), invalid months, infinite values, normalising months\n",
    "unseenData = removeOutliers(unseenData, forbiddenColumns)\n",
    "unseenData = filterInvalidMonthsNP(unseenData)\n",
    "unseenData = noIncludeInfinites(unseenData)\n",
    "unseenData = normaliseMonth(unseenData)\n",
    "\n",
    "\n",
    "#selecting correct columns for input and target data, drought (index 16) and SPI (index 14)\n",
    "unseenInput = unseenData[:, inputColumns]\n",
    "unseenTargetClassification = unseenData[:, 16]\n",
    "unseenTargetRegression = unseenData[:, 14]\n",
    "\n",
    "\n",
    "#normalising the unseen input data with min-max normalisation\n",
    "scalerUnseen = MinMaxScaler()\n",
    "scalerUnseen.fit(unseenInput)\n",
    "unseenInputNormalised = scalerUnseen.transform(unseenInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions and evaluations on unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting drought, binary classification on unseen data, threshold 0.5, 5.1e\n",
    "unseenClassPred = classificationModelLoaded.predict(unseenInputNormalised)\n",
    "unseenPredBin = (unseenClassPred >= 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "#plotting the confusion matrix and performance metrics\n",
    "print(\"Classification on unseen data:\")\n",
    "plotSimpleConfusionMatrix(unseenTargetClassification, unseenPredBin) #5.1f\n",
    "\n",
    "#5.1g\n",
    "print(\"Balanced Accuracy: \", balanced_accuracy_score(unseenTargetClassification, unseenPredBin))\n",
    "print(\"Precision: \", precision_score(unseenTargetClassification, unseenPredBin, pos_label=1))\n",
    "#5.1h\n",
    "print(\"Number of samples: \", len(unseenData))\n",
    "printPredictorsSet(allPredictors, inputColumns)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#predicting SPI on the unseen data, 5.2d\n",
    "unseenRegressionPred = regressionModelLoaded.predict(unseenInputNormalised)\n",
    "\n",
    "\n",
    "#scatter plot and performance metrics\n",
    "print(\"Regression on unseen data:\")\n",
    "scatterPlot(unseenTargetRegression, unseenRegressionPred) #5.2e\n",
    "#5.2f\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(unseenTargetRegression, unseenRegressionPred))\n",
    "print(\"Pearson Correlation Coefficient: \", r_regression(unseenRegressionPred, unseenTargetRegression))\n",
    "#5.2g\n",
    "print(\"Number of samples: \", len(unseenData))\n",
    "printPredictorsSet(allPredictors, inputColumns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
